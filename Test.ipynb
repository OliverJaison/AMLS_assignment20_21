{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'D:\\Admin\\Documents\\Year_4\\AMLS\\Assessment\\dataset_AMLS_20-21\\celeba\\img'\n",
    "labels_path = 'D:\\Admin\\Documents\\Year_4\\AMLS\\Assessment\\dataset_AMLS_20-21\\celeba\\labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "dft = pd.read_csv(labels_path, skiprows=lambda x: x in range(1,5000,5))\n",
    "dft[\"smiling\"] = dft[\"smiling\"].replace(to_replace=[-1], value=['Frown'])\n",
    "dft[\"smiling\"] = dft[\"smiling\"].replace(to_replace=[1], value=['Smile'])\n",
    "dft[\"gender\"] = dft[\"gender\"].replace(to_replace=[-1], value=['Female'])\n",
    "dft[\"gender\"] = dft[\"gender\"].replace(to_replace=[1], value=['Male'])\n",
    "one_hot_s = pd.get_dummies(dft[\"smiling\"])\n",
    "one_hot_g = pd.get_dummies(dft[\"gender\"])\n",
    "dft = dft.drop(columns=[\"gender\", \"smiling\"])\n",
    "dft = dft.join(one_hot_g)\n",
    "dft = dft.join(one_hot_s)\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=dft, \n",
    "    directory=file_path,\n",
    "    x_col=\"img_name\", \n",
    "    y_col=[\"Frown\", \"Smile\"], \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(55,45), \n",
    "    batch_size=100, \n",
    "    color_mode='grayscale', \n",
    "    interpolation='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 999 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "dfv = pd.read_csv(labels_path, skiprows=lambda x: x not in range(0,5000,5))\n",
    "dfv[\"smiling\"] = dfv[\"smiling\"].replace(to_replace=[-1], value=['Frown'])\n",
    "dfv[\"smiling\"] = dfv[\"smiling\"].replace(to_replace=[1], value=['Smile'])\n",
    "dfv[\"gender\"] = dfv[\"gender\"].replace(to_replace=[-1], value=['Female'])\n",
    "dfv[\"gender\"] = dfv[\"gender\"].replace(to_replace=[1], value=['Male'])\n",
    "one_hot_s = pd.get_dummies(dfv[\"smiling\"])\n",
    "one_hot_g = pd.get_dummies(dfv[\"gender\"])\n",
    "dfv = dfv.drop(columns=[\"gender\", \"smiling\"])\n",
    "dfv = dfv.join(one_hot_g)\n",
    "dfv = dfv.join(one_hot_s)\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=dfv, \n",
    "    directory=file_path,\n",
    "    x_col=\"img_name\", \n",
    "    y_col=[\"Frown\", \"Smile\"], \n",
    "    class_mode=\"raw\", \n",
    "    target_size=(55,45), \n",
    "    batch_size=100, \n",
    "    color_mode='grayscale', \n",
    "    interpolation='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(55,45,1)))\n",
    "model.add(Conv2D(filters=100, kernel_size=(3,3), strides=2, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Conv2D(filters=200, kernel_size=(2,2), strides=2, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Conv2D(filters=400,kernel_size=(2,2),activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_77 (Conv2D)           (None, 27, 22, 100)       1000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 27, 22, 100)       400       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 13, 11, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 6, 5, 200)         80200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 6, 5, 200)         800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 3, 2, 200)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 2, 1, 400)         320400    \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1024)              820224    \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 1,748,850\n",
      "Trainable params: 1,748,250\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = train_generator.n//train_generator.batch_size\n",
    "test_steps = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 12s 294ms/step - loss: 0.7849 - accuracy: 0.6105 - val_loss: 0.6917 - val_accuracy: 0.4911\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 13s 323ms/step - loss: 0.5479 - accuracy: 0.7312 - val_loss: 0.6908 - val_accuracy: 0.5150\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 12s 298ms/step - loss: 0.4495 - accuracy: 0.7843 - val_loss: 0.7086 - val_accuracy: 0.5250\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 11s 275ms/step - loss: 0.3752 - accuracy: 0.8353 - val_loss: 0.9376 - val_accuracy: 0.5050\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 11s 281ms/step - loss: 0.3228 - accuracy: 0.8583 - val_loss: 1.0056 - val_accuracy: 0.5095\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 11s 272ms/step - loss: 0.2629 - accuracy: 0.8842 - val_loss: 0.9777 - val_accuracy: 0.5039\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 11s 270ms/step - loss: 0.2199 - accuracy: 0.9047 - val_loss: 1.3228 - val_accuracy: 0.5228\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 11s 279ms/step - loss: 0.1715 - accuracy: 0.9300 - val_loss: 1.1391 - val_accuracy: 0.5195\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 12s 288ms/step - loss: 0.1312 - accuracy: 0.9482 - val_loss: 1.4573 - val_accuracy: 0.5095\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 11s 276ms/step - loss: 0.0966 - accuracy: 0.9657 - val_loss: 0.8433 - val_accuracy: 0.5617\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 11s 275ms/step - loss: 0.0644 - accuracy: 0.9822 - val_loss: 0.8097 - val_accuracy: 0.6511\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 12s 296ms/step - loss: 0.0427 - accuracy: 0.9898 - val_loss: 0.5163 - val_accuracy: 0.7253\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 11s 276ms/step - loss: 0.0295 - accuracy: 0.9962 - val_loss: 0.4628 - val_accuracy: 0.8176\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 11s 277ms/step - loss: 0.0336 - accuracy: 0.9905 - val_loss: 0.2630 - val_accuracy: 0.8699\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 11s 271ms/step - loss: 0.0212 - accuracy: 0.9965 - val_loss: 0.1995 - val_accuracy: 0.9499\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 11s 275ms/step - loss: 0.0143 - accuracy: 0.9977 - val_loss: 0.0556 - val_accuracy: 0.9722\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 11s 287ms/step - loss: 0.0136 - accuracy: 0.9983 - val_loss: 0.0425 - val_accuracy: 0.9878\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 13s 323ms/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 13s 322ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 11s 285ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 11s 286ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 12s 300ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 12s 292ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 8.9275e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.9291e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 11s 283ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.2854e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 11s 282ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.3168e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 11s 282ms/step - loss: 9.8164e-04 - accuracy: 1.0000 - val_loss: 5.1706e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 11s 277ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 5.3406e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 11s 283ms/step - loss: 8.8466e-04 - accuracy: 1.0000 - val_loss: 5.0122e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 13s 322ms/step - loss: 9.3058e-04 - accuracy: 1.0000 - val_loss: 4.6356e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 15s 377ms/step - loss: 7.8759e-04 - accuracy: 1.0000 - val_loss: 3.9391e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 14s 356ms/step - loss: 6.1560e-04 - accuracy: 1.0000 - val_loss: 3.0178e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 15s 373ms/step - loss: 7.2688e-04 - accuracy: 1.0000 - val_loss: 4.7220e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 15s 363ms/step - loss: 5.9623e-04 - accuracy: 1.0000 - val_loss: 3.3230e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 15s 363ms/step - loss: 5.7947e-04 - accuracy: 1.0000 - val_loss: 2.3243e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 14s 356ms/step - loss: 5.1988e-04 - accuracy: 1.0000 - val_loss: 3.2712e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 14s 352ms/step - loss: 5.2911e-04 - accuracy: 1.0000 - val_loss: 3.0872e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 14s 356ms/step - loss: 4.5116e-04 - accuracy: 1.0000 - val_loss: 1.8447e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 15s 375ms/step - loss: 4.1624e-04 - accuracy: 1.0000 - val_loss: 2.1468e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 13s 315ms/step - loss: 3.7436e-04 - accuracy: 1.0000 - val_loss: 2.0421e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 14s 348ms/step - loss: 4.0897e-04 - accuracy: 1.0000 - val_loss: 1.9609e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 13s 331ms/step - loss: 4.0689e-04 - accuracy: 1.0000 - val_loss: 1.9078e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 15s 372ms/step - loss: 3.4162e-04 - accuracy: 1.0000 - val_loss: 1.5679e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 15s 364ms/step - loss: 3.2642e-04 - accuracy: 1.0000 - val_loss: 1.6425e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 15s 371ms/step - loss: 2.9422e-04 - accuracy: 1.0000 - val_loss: 1.7754e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 3.0746e-04 - accuracy: 1.0000 - val_loss: 1.7052e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 2.5798e-04 - accuracy: 1.0000 - val_loss: 1.0277e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 2.4160e-04 - accuracy: 1.0000 - val_loss: 9.7056e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 15s 375ms/step - loss: 2.5346e-04 - accuracy: 1.0000 - val_loss: 1.6072e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x299b5e42c18>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator, \n",
    "                    steps_per_epoch=train_steps,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=test_steps,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
