{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I initialise the file paths for the images and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'D:\\Admin\\Documents\\Year_4\\AMLS\\Assessment\\dataset_AMLS_20-21\\celeba\\img'\n",
    "labels_path = 'D:\\Admin\\Documents\\Year_4\\AMLS\\Assessment\\dataset_AMLS_20-21\\celeba\\labels.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I import the images and labels into a training data frame using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr = pd.read_csv(labels_path)\n",
    "\n",
    "dftr[\"smiling\"] = dftr[\"smiling\"].replace(to_replace=[-1], value=['Frown'])\n",
    "dftr[\"smiling\"] = dftr[\"smiling\"].replace(to_replace=[1], value=['Smile'])\n",
    "dftr[\"gender\"] = dftr[\"gender\"].replace(to_replace=[-1], value=['Female'])\n",
    "dftr[\"gender\"] = dftr[\"gender\"].replace(to_replace=[1], value=['Male'])\n",
    "\n",
    "one_hot_s = pd.get_dummies(dftr[\"smiling\"])\n",
    "one_hot_g = pd.get_dummies(dftr[\"gender\"])\n",
    "dftr = dftr.drop(columns=[\"gender\", \"smiling\"])\n",
    "dftr = dftr.join(one_hot_g)\n",
    "dftr = dftr.join(one_hot_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I do the same thing but for a testing data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = \\\n",
    "              np.split(dftr.sample(frac=1), \n",
    "                       [int(.6*len(dftr)), int(.8*len(dftr))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 validated image filenames.\n",
      "Found 1000 validated image filenames.\n",
      "Found 1000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=train, \n",
    "                                              directory=file_path, \n",
    "                                              x_col=\"img_name\", \n",
    "                                              y_col=[\"Frown\", \"Smile\"], \n",
    "                                              class_mode=\"raw\", \n",
    "                                              target_size=(55,45), \n",
    "                                              batch_size=30, \n",
    "                                              color_mode='grayscale', \n",
    "                                              interpolation='bicubic')\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(dataframe=validation, \n",
    "                                              directory=file_path, \n",
    "                                              x_col=\"img_name\", \n",
    "                                              y_col=[\"Frown\", \"Smile\"], \n",
    "                                              class_mode=\"raw\", \n",
    "                                              target_size=(55,45), \n",
    "                                              batch_size=10, \n",
    "                                              color_mode='grayscale', \n",
    "                                              interpolation='bicubic')\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=test, \n",
    "                                              directory=file_path, \n",
    "                                              x_col=\"img_name\", \n",
    "                                              y_col=[\"Frown\", \"Smile\"], \n",
    "                                              class_mode=\"raw\", \n",
    "                                              target_size=(55,45), \n",
    "                                              batch_size=10, \n",
    "                                              color_mode='grayscale', \n",
    "                                              interpolation='bicubic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code generates batches of data to feed into the neural network architecture below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(55,45,1)))\n",
    "model.add(Conv2D(filters=100, kernel_size=(3,3), strides=2, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Conv2D(filters=200, kernel_size=(2,2), strides=2, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Conv2D(filters=400,kernel_size=(2,2),activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code just compiles the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = train_generator.n//train_generator.batch_size\n",
    "validation_steps = validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code just trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.7783 - accuracy: 0.6340 - val_loss: 0.6828 - val_accuracy: 0.6160\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.5102 - accuracy: 0.7513 - val_loss: 0.6514 - val_accuracy: 0.6650\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.3843 - accuracy: 0.8270 - val_loss: 0.5616 - val_accuracy: 0.6810\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.3098 - accuracy: 0.8600 - val_loss: 0.4807 - val_accuracy: 0.7230\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.2567 - accuracy: 0.8893 - val_loss: 0.3237 - val_accuracy: 0.7700\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.1930 - accuracy: 0.9170 - val_loss: 0.2732 - val_accuracy: 0.7860\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.1279 - accuracy: 0.9523 - val_loss: 0.6755 - val_accuracy: 0.7870\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.0720 - accuracy: 0.9780 - val_loss: 0.1742 - val_accuracy: 0.7810\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.0438 - accuracy: 0.9867 - val_loss: 1.9014 - val_accuracy: 0.7700\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 0.0652 - val_accuracy: 0.7900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19eee04edd8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator, \n",
    "                    steps_per_epoch=train_steps,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44790253043174744, 0.8040000200271606]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
