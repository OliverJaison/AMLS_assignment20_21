{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will contain my first attempt at multiclass classification problem for cartoon faces\n",
    "Here we import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import dlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from keras.preprocessing import image\n",
    "from sklearn import decomposition\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mapimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:\\Admin\\Documents\\Year_4\\AMLS\\Assessment\\dataset_AMLS_20-21\\cartoon_set\\img\"\n",
    "labels_path = \"D:\\Admin\\Documents\\Year_4\\AMLS\\Assessment\\dataset_AMLS_20-21\\cartoon_set\\labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(labels_path)\n",
    "\n",
    "df = df.drop(columns=\"Unnamed: 0\")\n",
    "temp = df[\"file_name\"]\n",
    "df.insert(loc=0, column=\"file_names\", value=temp)\n",
    "df = df.drop(columns=\"file_name\")\n",
    "df = df.drop(df.index[1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = \\\n",
    "              np.split(df.sample(frac=1), \n",
    "                       [int(.6*len(df)), int(.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    coords = np.zeros((shape.num_parts, 2), dtype=dtype)\n",
    "    for i in range(0, shape.num_parts):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rect_to_dim(rect):\n",
    "    w = rect.right() - rect.left()\n",
    "    h = rect.top() - rect.bottom()\n",
    "    return (w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature(img):\n",
    "    face_detect = dlib.get_frontal_face_detector()\n",
    "    shape_predict = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = gray.astype('uint8')\n",
    "    rects = face_detect(gray, 1)\n",
    "    num_faces = len(rects)\n",
    "    \n",
    "    if num_faces == 0:\n",
    "        return None\n",
    "\n",
    "    face_areas = np.zeros((1, num_faces))\n",
    "    face_shapes = np.zeros((136, num_faces), dtype=np.int64)\n",
    "    \n",
    "    for (i, rect) in enumerate(rects):\n",
    "        temp_shape = shape_predict(gray, rect)\n",
    "        temp_shape = shape_to_np(temp_shape)\n",
    "        (w, h) = rect_to_dim(rect)\n",
    "        face_shapes[:, i] = np.reshape(temp_shape, [136])\n",
    "        face_areas[0, i] = w * h\n",
    "        dlibout = np.reshape(np.transpose(face_shapes[:, np.argmax(face_areas)]), [68, 2])\n",
    "    return dlibout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(file_path, train_df):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for file_name in train_df[\"file_names\"]:\n",
    "        img_path = os.path.join(file_path, file_name)\n",
    "        img = cv2.imread(img_path, 0)\n",
    "        feature = hog(img, pixels_per_cell=(6,6))\n",
    "        if feature is not None:\n",
    "            features.append(feature)\n",
    "            temp = file_name.split(\".\")[0]\n",
    "            labels.append(train_df.loc[int(temp), \"face_shape\"])\n",
    "    features = np.array(features)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = create_feature_matrix(file_path, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 531441)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split the data to test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier = svm.SVC(kernel='poly', degree=3, C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = metrics.accuracy_score(y_test,y_pred=y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_x, valid_y = create_feature_matrix(file_path, validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split the data to test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(valid_x)\n",
    "accuracy = metrics.accuracy_score(valid_y, y_pred=y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
